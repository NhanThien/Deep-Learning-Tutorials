{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2seq with Attention.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "glSMYyrQmpxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.contrib import rnn\n",
        "\n",
        "class Seq2SeqModel(object):\n",
        "  def __init__(self,vocab_size, word_embedding, input_len, output_len, params, train=True):\n",
        "    # Get the vocab size\n",
        "    self.vocab_size=vocab_size\n",
        "    \n",
        "    # Get hyper-parameters from params       \n",
        "    self.num_layers=params['num_layers']\n",
        "    self.num_hiddens=params['num_hiddens']    \n",
        "    self.learning_rate = params['learning_rate']\n",
        "    self.keep_prob = params['keep_prob']\n",
        "    self.beam_width = params['beam_width']\n",
        "    \n",
        "    # Using BasicLSTMCell as a cell unit\n",
        "    self.cell=tf.nn.rnn_cell.LSTMCell  \n",
        "    \n",
        "    # Define Place holders for the model\n",
        "    self.batch_size=tf.placeholder(tf.int32,(),name=\"batch_size\")\n",
        "    self.global_step = tf.Variable(0, trainable=False) # False means not adding the variable to the graph collection \n",
        "    \n",
        "    # place holders for encoder\n",
        "    self.inputSeq=tf.placeholder(tf.int32,[None,input_len])\n",
        "    self.inputSeq_len=tf.placeholder(tf.int32, [None]) # Need to define the Shape as required in tf.contrib.seq2seq.tile_batch\n",
        "    \n",
        "    # place holders for decoder\n",
        "    self.decoder_input=tf.placeholder(tf.int32,[None,output_len])\n",
        "    self.decoder_len=tf.placeholder(tf.int32, [None])\n",
        "    self.decoder_target=tf.placeholder(tf.int32,[None,output_len])\n",
        "    \n",
        "    # Define projection_layer\n",
        "    self.projection_layer = tf.layers.Dense(self.vocab_size, use_bias=False)\n",
        "    \n",
        "    # Define the Embedding layer\n",
        "    with tf.name_scope(\"embedding\"):\n",
        "      self.embeddings=tf.get_variable(\"embeddings\",initializer=tf.constant(word_embedding,dtype=tf.float32))\n",
        "      \n",
        "      # map the int value with its embeddings\n",
        "      input_emb=tf.nn.embedding_lookup(self.embeddings,self.inputSeq)\n",
        "      decoder_input_emb=tf.nn.embedding_lookup(self.embeddings,self.decoder_input)\n",
        "      \n",
        "      # Convert from batch_size*seq_len*embedding to seq_len*batch_size*embedding to feed data with timestep      \n",
        "      # But, we need to set time_major=True during Training\n",
        "      self.encoder_inputEmb = tf.transpose(input_emb, perm=[1, 0, 2])\n",
        "      self.decoder_inputEmb = tf.transpose(decoder_input_emb, perm=[1, 0, 2])\n",
        "      \n",
        "    # Define the Encoder\n",
        "    with tf.name_scope(\"encoder\"):      \n",
        "      # Create RNN Cell for forward and backward direction\n",
        "      fw_cells=list()\n",
        "      bw_cells=list()\n",
        "      for i in range(self.num_layers):\n",
        "        fw_cell= self.cell(self.num_hiddens)\n",
        "        bw_cell= self.cell(self.num_hiddens)\n",
        "        \n",
        "        # Add Dropout\n",
        "        fw_cell=rnn.DropoutWrapper(fw_cell,output_keep_prob=self.keep_prob)\n",
        "        bw_cell=rnn.DropoutWrapper(bw_cell,output_keep_prob=self.keep_prob)\n",
        "        \n",
        "        # Add cell to the list\n",
        "        fw_cells.append(fw_cell)\n",
        "        bw_cells.append(bw_cell)\n",
        "        \n",
        "        \n",
        "      # Build a multi bi-directional model from fw_cells and bw_cells\n",
        "      outputs, encoder_state_fw, encoder_state_bw = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(\n",
        "          cells_fw=fw_cells, cells_bw=bw_cells,inputs=self.encoder_inputEmb,time_major=True, sequence_length=self.inputSeq_len, dtype=tf.float32)\n",
        "      \n",
        "      # The ouput of Encoder (time major)\n",
        "      self.encoder_outputs=outputs\n",
        "      \n",
        "      # Use the final state of the last layer as encoder_final_state \n",
        "      encoder_state_c = tf.concat((encoder_state_fw[-1].c, encoder_state_bw[-1].c), 1)\n",
        "      encoder_state_h = tf.concat((encoder_state_fw[-1].h, encoder_state_bw[-1].h), 1)\n",
        "      self.encoder_final_state = rnn.LSTMStateTuple(c=encoder_state_c, h=encoder_state_h)\n",
        "      \n",
        "    # Define the Decoder for training\n",
        "    with tf.name_scope(\"decoder\"):\n",
        "      # Define Decoder cell\n",
        "      decoder_num_hiddens =self.num_hiddens * 2 # As we use bi-directional RNN\n",
        "      decoder_cell=self.cell(decoder_num_hiddens)\n",
        "      \n",
        "      # Training mode \n",
        "      if(train):\n",
        "        # Convert from time major to batch major \n",
        "        attention_states = tf.transpose(self.encoder_outputs, [1, 0, 2])\n",
        "        \n",
        "         # Decoder with attention      \n",
        "        attention=tf.contrib.seq2seq.BahdanauAttention(num_units=decoder_num_hiddens, memory=attention_states, memory_sequence_length=self.inputSeq_len,normalize=True)\n",
        "        attention_decoder_cell= tf.contrib.seq2seq.AttentionWrapper(cell=decoder_cell,attention_mechanism=attention,attention_layer_size=decoder_num_hiddens)\n",
        "\n",
        "        # Use the final state of encoder as the initial state of the decoder\n",
        "        decoder_initial_state = attention_decoder_cell.zero_state(dtype=tf.float32, batch_size=self.batch_size)\n",
        "        decoder_initial_state = decoder_initial_state.clone(cell_state=self.encoder_final_state )\n",
        "\n",
        "        # Use TrainingHelper to train the Model \n",
        "        training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=self.decoder_inputEmb,sequence_length=self.decoder_len, time_major=True)\n",
        "        decoder = tf.contrib.seq2seq.BasicDecoder(cell=attention_decoder_cell,helper=training_helper,initial_state=decoder_initial_state,output_layer=self.projection_layer)\n",
        "        logits, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, output_time_major=True,maximum_iterations=output_len)\n",
        "        \n",
        "        \n",
        "        # Convert from time major to batch major \n",
        "        self.training_logits = tf.transpose(logits.rnn_output, perm=[1, 0, 2])\n",
        "        \n",
        "        # Adding zero to make sure training_logits has shape: [batch_size, sequence_length, num_decoder_symbols]\n",
        "        self.training_logits = tf.concat([self.training_logits, tf.zeros([self.batch_size, output_len - tf.shape(self.training_logits)[1], self.vocab_size])], axis=1)\n",
        "     \n",
        "      # Inference mode \n",
        "      else:\n",
        "        # Using Beam search\n",
        "        tiled_encoder_outputs = tf.contrib.seq2seq.tile_batch(tf.transpose(self.encoder_outputs, perm=[1, 0, 2]), multiplier=self.beam_width)\n",
        "        tiled_encoder_final_state=tf.contrib.seq2seq.tile_batch(self.encoder_final_state, multiplier=self.beam_width)\n",
        "        tiled_inputSeq_len=tf.contrib.seq2seq.tile_batch(self.inputSeq_len, multiplier=self.beam_width)\n",
        "\n",
        "        # Decoder with attention with Beam search\n",
        "        attention=tf.contrib.seq2seq.BahdanauAttention(num_units=decoder_num_hiddens, memory=tiled_encoder_outputs, memory_sequence_length=tiled_inputSeq_len,normalize=True)\n",
        "        attention_decoder_cell= tf.contrib.seq2seq.AttentionWrapper(cell=decoder_cell,attention_mechanism=attention,attention_layer_size=decoder_num_hiddens)\n",
        "\n",
        "        # Use the final state of encoder as the initial state of the decoder\n",
        "        decoder_initial_state = attention_decoder_cell.zero_state(dtype=tf.float32, batch_size=self.batch_size * self.beam_width)\n",
        "        decoder_initial_state = decoder_initial_state.clone(cell_state=tiled_encoder_final_state)\n",
        "\n",
        "        # Build a Decoder with Beam Search\n",
        "        beamSearch_decoder=tf.contrib.seq2seq.BeamSearchDecoder(          \n",
        "            cell=attention_decoder_cell,\n",
        "            embedding=self.embeddings,\n",
        "            start_tokens=tf.fill([self.batch_size],tf.constant(2)),\n",
        "            end_token=tf.constant(3),\n",
        "            initial_state=decoder_initial_state,\n",
        "            beam_width=self.beam_width,\n",
        "            output_layer=self.projection_layer  \n",
        "        )\n",
        "\n",
        "        # Perform dynamic decoding with beamSearch_decoder\n",
        "        outputs, _ , _ =tf.contrib.seq2seq.dynamic_decode(decoder=beamSearch_decoder,maximum_iterations= output_len,output_time_major=True)\n",
        "        \n",
        "        # Convert from seq_len*batch_size*beam_width to batch_size*beam_width*seq_len\n",
        "        outputs=tf.transpose(outputs.predicted_ids, perm=[1, 2, 0])\n",
        "        \n",
        "        # Take the first beam (best result) as Decoder ouput \n",
        "        self.decoder_outputs=outputs[:,0,:]\n",
        "\n",
        "    with tf.name_scope(\"optimization\"):\n",
        "      # Used for Training mode only \n",
        "      if(train):\n",
        "        # Caculate loss value \n",
        "        masks = tf.sequence_mask(lengths=self.decoder_len,maxlen=output_len, dtype=tf.float32)         \n",
        "        self.loss = tf.contrib.seq2seq.sequence_loss(logits=self.training_logits,targets=self.decoder_target,weights=masks)\n",
        "\n",
        "        # Using AdamOptimizer\n",
        "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
        "        # Compute gradient \n",
        "        gradients = optimizer.compute_gradients(self.loss)\n",
        "        # Apply Gradient Clipping \n",
        "        gradients_clipping = [(tf.clip_by_value(grad, clip_value_min=-5., clip_value_max=5.), var) for grad, var in gradients if grad is not None]\n",
        "\n",
        "        # Apply gradients to variables\n",
        "        self.train_update = optimizer.apply_gradients(gradients_clipping, global_step=self.global_step)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}