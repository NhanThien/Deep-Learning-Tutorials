{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Using tf.data API.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "egAEPCkRi2Ce",
        "colab_type": "code",
        "outputId": "48ccf0dc-c1c1-42c9-c6f9-4a28406c66ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create dataset from numpy\n",
        "np_data=np.random.sample((100,2))\n",
        "numpy_dataset=tf.data.Dataset.from_tensor_slices(np_data)\n",
        "\n",
        "\n",
        "# Create dataset from tensor\n",
        "tensor_data=tf.random_uniform([100,2])\n",
        "tensor_dataset=tf.data.Dataset.from_tensor_slices(tensor_data)\n",
        "\n",
        "# Print the first element of the dataset using Iterator\n",
        "def printDataset(dataset):\n",
        "  iterator=dataset.make_initializable_iterator()\n",
        "  element=iterator.get_next()\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(iterator.initializer)\n",
        "    print(sess.run(element))\n",
        "\n",
        "print(\"\\nThe first element of the numpy_dataset:\")\n",
        "printDataset(numpy_dataset)\n",
        "print(\"\\nThe first element of the tensor_dataset:\")\n",
        "printDataset(tensor_dataset)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "The first element of the numpy_dataset:\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "[0.02523586 0.04324205]\n",
            "\n",
            "The first element of the tensor_dataset:\n",
            "[0.99107265 0.05335832]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTBNJEp6OzUP",
        "colab_type": "code",
        "outputId": "cba8cf92-2ad2-43df-bb7d-dd4097c0a987",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "x_data=np.arange(0,10)\n",
        "y_data=np.arange(50,60)\n",
        "\n",
        "# Create dataset from numpy\n",
        "x_dataset=tf.data.Dataset.from_tensor_slices(x_data)\n",
        "y_dataset=tf.data.Dataset.from_tensor_slices(y_data)\n",
        "\n",
        "# Zip two dataset\n",
        "train_dataset=tf.data.Dataset.zip((x_dataset,y_dataset))\n",
        "\n",
        "# Create batches with size=3\n",
        "train_dataset=train_dataset.batch(batch_size=3)\n",
        "\n",
        "print(\"\\nThe first run:\")\n",
        "printDataset(train_dataset)\n",
        "print(\"\\nThe second run:\")\n",
        "printDataset(train_dataset)\n",
        "\n",
        "# Shuffle the dataset\n",
        "train_dataset=train_dataset.shuffle(buffer_size=100)\n",
        "print(\"\\nAfter shuffling data:\")\n",
        "print(\"The first run:\")\n",
        "printDataset(train_dataset)\n",
        "print(\"\\nThe second run:\")\n",
        "printDataset(train_dataset)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "The first run:\n",
            "(array([0, 1, 2]), array([50, 51, 52]))\n",
            "\n",
            "The second run:\n",
            "(array([0, 1, 2]), array([50, 51, 52]))\n",
            "\n",
            "After shuffling data:\n",
            "The first run:\n",
            "(array([0, 1, 2]), array([50, 51, 52]))\n",
            "\n",
            "The second run:\n",
            "(array([3, 4, 5]), array([53, 54, 55]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7HqrhNGReTN",
        "colab_type": "code",
        "outputId": "559b1591-db34-4612-9f02-920616080d3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1445
        }
      },
      "source": [
        "# Example of using One-shot Iterator\n",
        "one_shot_dataset=tf.data.Dataset.range(10)\n",
        "\n",
        "# Create an one_shot iterator\n",
        "iterator=one_shot_dataset.make_one_shot_iterator()\n",
        "next_element=iterator.get_next()\n",
        "\n",
        "sess=tf.Session()\n",
        "for i in range(10):\n",
        "  print(sess.run(next_element),end=' ')\n",
        "\n",
        "# OutOfRangeError occurs as Iterator already reaches the end of the dataset\n",
        "print(sess.run(next_element))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1 2 3 4 5 6 7 8 9 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OutOfRangeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence\n\t [[{{node IteratorGetNext_26}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-f69e18bcd579>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Error occurs as One-shot Iterator only interates once through the dataset(OutOfRangeError)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence\n\t [[node IteratorGetNext_26 (defined at <ipython-input-27-f69e18bcd579>:5) ]]\n\nCaused by op 'IteratorGetNext_26', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-27-f69e18bcd579>\", line 5, in <module>\n    next_element=iterator.get_next()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 414, in get_next\n    output_shapes=self._structure._flat_shapes, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1685, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nOutOfRangeError (see above for traceback): End of sequence\n\t [[node IteratorGetNext_26 (defined at <ipython-input-27-f69e18bcd579>:5) ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzL1wCCwmwte",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "5ea74520-a354-40f3-dd76-e5179857ee0a"
      },
      "source": [
        "# Example of using Initializable Iterator\n",
        "max_value=tf.placeholder(tf.int64)\n",
        "init_dataset=tf.data.Dataset.range(max_value)\n",
        "\n",
        "# Create an initializable iterator\n",
        "iterator=init_dataset.make_initializable_iterator()\n",
        "next_element=iterator.get_next()\n",
        "\n",
        "# Create a tensorflow session\n",
        "sess=tf.Session()\n",
        "\n",
        "# Create a dataset with 5 data\n",
        "sess.run(iterator.initializer, feed_dict={max_value:5})\n",
        "print('Dataset with 5 data: ')\n",
        "for i in range(5):\n",
        "  print(sess.run(next_element),end=' ')\n",
        "\n",
        "# Create a dataset with 8 data\n",
        "sess.run(iterator.initializer, feed_dict={max_value:8})\n",
        "print('\\n\\nDataset with 8 data: ')\n",
        "for i in range(8):\n",
        "  print(sess.run(next_element),end=' ')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset with 5 data: \n",
            "0 1 2 3 4 \n",
            "\n",
            "Dataset with 8 data: \n",
            "0 1 2 3 4 5 6 7 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HP3YH1xMdMJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7d287687-e6eb-4dbe-f114-7281bfb6cf3f"
      },
      "source": [
        "# Example of using Reinitializable Iterator\n",
        "\n",
        "# Create two datasets with the same structure \n",
        "train_dataset=tf.data.Dataset.range(10)\n",
        "test_dataset=tf.data.Dataset.range(5)\n",
        "\n",
        "# Create a reinitializable iterator defined by its structure\n",
        "iterator=tf.data.Iterator.from_structure(train_dataset.output_types,train_dataset.output_shapes)\n",
        "next_element=iterator.get_next()\n",
        "\n",
        "# Create initialization operation for each dataset \n",
        "train_init_op=iterator.make_initializer(train_dataset)\n",
        "test_init_op=iterator.make_initializer(test_dataset)\n",
        "\n",
        "# Create a tensorflow session\n",
        "sess=tf.Session()\n",
        "\n",
        "# Get the train data\n",
        "sess.run(train_init_op)\n",
        "print('Train dataset: ')\n",
        "for i in range(10):\n",
        "  print(sess.run(next_element),end=' ')\n",
        "\n",
        "# Switch from train_dataset to test_dataset\n",
        "sess.run(test_init_op)\n",
        "print('\\n\\nTest dataset: ')\n",
        "for i in range(5):\n",
        "  print(sess.run(next_element),end=' ')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train dataset: \n",
            "0 1 2 3 4 5 6 7 8 9 \n",
            "\n",
            "Test dataset: \n",
            "0 1 2 3 4 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VCc2K-HPDSm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6478b63c-676e-4c75-fc48-c8163b7ee206"
      },
      "source": [
        "# Example of using Feedable Iterator\n",
        "\n",
        "# Create two datasets with the same structure \n",
        "train_dataset=tf.data.Dataset.range(10)\n",
        "test_dataset=tf.data.Dataset.range(5)\n",
        "\n",
        "# Create a feedable iterator defined by a placeholder and its structure\n",
        "handle=tf.placeholder(tf.string)\n",
        "iterator=tf.data.Iterator.from_string_handle(handle,train_dataset.output_types,train_dataset.output_shapes)\n",
        "next_element=iterator.get_next()\n",
        "\n",
        "# Create one-shot iterator for train_dataset \n",
        "train_iterator=train_dataset.make_one_shot_iterator()\n",
        "\n",
        "# Create initializable iterator for test_dataset \n",
        "test_iterator=test_dataset.make_initializable_iterator()\n",
        "\n",
        "# Create a tensorflow session\n",
        "sess=tf.Session()\n",
        "\n",
        "# Create handle for train_iterator and test_iterator\n",
        "train_handle=sess.run(train_iterator.string_handle())\n",
        "test_handle=sess.run(test_iterator.string_handle())\n",
        "\n",
        "\n",
        "# Get the train data using train_iterator\n",
        "print('Train dataset(using one-shot iterator): ')\n",
        "for i in range(10):\n",
        "  print(sess.run(next_element, feed_dict={handle:train_handle}),end=' ')\n",
        "\n",
        "# Switch from one-shot iterator to initializable iterator\n",
        "sess.run(test_iterator.initializer)\n",
        "print('\\n\\nTest dataset(using initializable iterator): ')\n",
        "for i in range(5):\n",
        "  print(sess.run(next_element, feed_dict={handle:test_handle}),end=' ')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train dataset(using one-shot iterator): \n",
            "0 1 2 3 4 5 6 7 8 9 \n",
            "\n",
            "Test dataset(using initializable iterator): \n",
            "0 1 2 3 4 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HKzLDD6ZtD9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "0eaee88b-e317-4b5c-bb6f-12531ace29e3"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load and processing the data\n",
        "wine_data = datasets.load_wine()\n",
        "data=wine_data['data']\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "data_scaled = min_max_scaler.fit_transform(data)\n",
        "\n",
        "#Split into train and test set\n",
        "train_data, test_data, train_label, test_label = train_test_split(data_scaled,wine_data['target'],test_size=0.2)\n",
        "\n",
        "# Create a dataset from train_data,train_label\n",
        "tf.reset_default_graph() \n",
        "epoches=50\n",
        "train_dataset=tf.data.Dataset.from_tensor_slices((train_data,train_label)).repeat(epoches).batch(len(train_data))\n",
        "\n",
        "# Create an one-shot iterator\n",
        "iterator = train_dataset.make_one_shot_iterator()\n",
        "inputData, actual_labels = iterator.get_next()\n",
        "\n",
        "# Create a neural network\n",
        "hidden1=tf.layers.dense(inputData,128,activation=tf.nn.relu,name=\"layer1\")\n",
        "hidden2=tf.layers.dense(hidden1,64,activation=tf.nn.relu,name=\"layer2\")\n",
        "logit=tf.layers.dense(hidden2,3,name=\"logit\")\n",
        "\n",
        "# Define the loss function and Optimization algorithm\n",
        "cross_entropy=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=train_label,logits=logit)\n",
        "loss=tf.reduce_mean(cross_entropy,name=\"loss\")\n",
        "training_op=tf.train.AdamOptimizer(0.01).minimize(loss)    \n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy=tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logit,1),actual_labels),tf.float64))\n",
        "\n",
        "# Create a session and initialse all variables                       \n",
        "sess=tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for i in range(epoches):\n",
        "  # Train the model and calculate the accuracy of the current model\n",
        "  _,train_accuracy=sess.run([training_op,accuracy])\n",
        "  \n",
        "  # Display the accuracy result\n",
        "  print(i+1,'. Train accuracy: ',train_accuracy)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 . Train accuracy:  0.23943661971830985\n",
            "2 . Train accuracy:  0.6338028169014085\n",
            "3 . Train accuracy:  0.704225352112676\n",
            "4 . Train accuracy:  0.823943661971831\n",
            "5 . Train accuracy:  0.9507042253521126\n",
            "6 . Train accuracy:  0.9436619718309859\n",
            "7 . Train accuracy:  0.9577464788732394\n",
            "8 . Train accuracy:  0.971830985915493\n",
            "9 . Train accuracy:  0.971830985915493\n",
            "10 . Train accuracy:  0.971830985915493\n",
            "11 . Train accuracy:  0.9788732394366197\n",
            "12 . Train accuracy:  0.9788732394366197\n",
            "13 . Train accuracy:  0.9788732394366197\n",
            "14 . Train accuracy:  0.9859154929577465\n",
            "15 . Train accuracy:  0.9859154929577465\n",
            "16 . Train accuracy:  0.9929577464788732\n",
            "17 . Train accuracy:  0.9929577464788732\n",
            "18 . Train accuracy:  0.9929577464788732\n",
            "19 . Train accuracy:  0.9929577464788732\n",
            "20 . Train accuracy:  0.9929577464788732\n",
            "21 . Train accuracy:  0.9929577464788732\n",
            "22 . Train accuracy:  0.9929577464788732\n",
            "23 . Train accuracy:  1.0\n",
            "24 . Train accuracy:  1.0\n",
            "25 . Train accuracy:  1.0\n",
            "26 . Train accuracy:  1.0\n",
            "27 . Train accuracy:  1.0\n",
            "28 . Train accuracy:  1.0\n",
            "29 . Train accuracy:  1.0\n",
            "30 . Train accuracy:  1.0\n",
            "31 . Train accuracy:  1.0\n",
            "32 . Train accuracy:  1.0\n",
            "33 . Train accuracy:  1.0\n",
            "34 . Train accuracy:  1.0\n",
            "35 . Train accuracy:  1.0\n",
            "36 . Train accuracy:  1.0\n",
            "37 . Train accuracy:  1.0\n",
            "38 . Train accuracy:  1.0\n",
            "39 . Train accuracy:  1.0\n",
            "40 . Train accuracy:  1.0\n",
            "41 . Train accuracy:  1.0\n",
            "42 . Train accuracy:  1.0\n",
            "43 . Train accuracy:  1.0\n",
            "44 . Train accuracy:  1.0\n",
            "45 . Train accuracy:  1.0\n",
            "46 . Train accuracy:  1.0\n",
            "47 . Train accuracy:  1.0\n",
            "48 . Train accuracy:  1.0\n",
            "49 . Train accuracy:  1.0\n",
            "50 . Train accuracy:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w61pzNegb_1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
